{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee216ac-cbc1-4576-a6c2-74e6ae2ff2c9",
   "metadata": {},
   "source": [
    "# 6.4: Resampling Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451fa372-7eb2-43e8-bbf5-429bc446f0a0",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "### Import Libraries \n",
    "\n",
    "We import our standard libraries and specific objects/libraries at the top level of our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbc31d-be7c-4dd3-bb07-a9f681754433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our previous libraries and objects\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import new libraries and objects\n",
    "from functools import partial\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                         test_size=196, # split in two\n",
    "                                         random_state=0) # random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2be2e8-fc23-4137-8537-ec035ffdfa0f",
   "metadata": {},
   "source": [
    "## The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5bbf66-b518-430a-8def-51eae4edba7c",
   "metadata": {},
   "source": [
    "The bootstrap approach can be applied in almost all situations. While there are several implementations of the bootstrap in Python, its use for estimating standard error is simple enough that we write our own function below for the case when our data is stored in a dataframe. We will use the `Portfolio` data set in the `ISLP` package to illustrate.\n",
    "\n",
    "We will create a function `alpha_func()`, which takes as input a dataframe `D` assumed\n",
    "to have columns `X` and `Y`, as well as a\n",
    "vector `idx` indicating which observations should be used to\n",
    "estimate \n",
    "$\\alpha$. The function then outputs the estimate for $\\alpha$ based on\n",
    "the selected observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd0632-1ae7-463e-8e0f-6504fb70f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "   cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "   return ((cov_[1,1] - cov_[0,1]) /\n",
    "           (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244b3fc-be11-4566-8dcf-603e0035e796",
   "metadata": {},
   "source": [
    "The following command estimates $\\alpha$ using all 100 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4973de-b821-4af8-8e0f-61befe6d86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e226aa-b7cf-49cc-9b57-2b716e163457",
   "metadata": {},
   "source": [
    "Next we randomly select 100 observations from range(100), with replacement. This is equivalent to constructing a new bootstrap data set and recomputing $\\alpha$ based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfd7c4-02b0-45ad-99f4-616ace0f044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio,\n",
    "           rng.choice(100,\n",
    "                      100,\n",
    "                      replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee315a5-d48e-4c57-b406-c2940c04e794",
   "metadata": {},
   "source": [
    "This process can be generalized to create a simple function `boot_SE()` for computing the bootstrap standard error for arbitrary functions that take only a data frame as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c616715-c7e3-4230-a313-58ba81bdd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "def boot_SE(func,\n",
    "            D,\n",
    "            n=None,\n",
    "            B=1000,\n",
    "            seed=0):\n",
    "    # NOTE: Suppress FutureWarning in ISLP.models.columns\n",
    "    # The warning is related to Series.__getitem__ treating keys as positions, which is deprecated.\n",
    "    # Since ISLP is an external library that I don't control, and this specific warning does not\n",
    "    # affect my current usage, I'm suppressing it to keep the output clean and focused on relevant information.\n",
    "    warnings.filterwarnings(action='ignore', category=FutureWarning, module='ISLP.models.columns', lineno=151)\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index,\n",
    "                         n,\n",
    "                         replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49225f-368c-467a-90c8-be415fc10a46",
   "metadata": {},
   "source": [
    "Letâ€™s use our function to evaluate the accuracy of our estimate of $\\alpha$ using $B = 1,000$ bootstrap replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c693db4-e496-4c57-99db-f558c6213874",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_SE = boot_SE(alpha_func,\n",
    "                   Portfolio,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee815d-2369-45bb-862f-baddb290820d",
   "metadata": {},
   "source": [
    "The final output shows that the bootstrap estimate for ${\\rm SE}(\\hat{\\alpha})$ is $0.0912$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b759abb-913b-40bf-b11e-890681f1f9e4",
   "metadata": {},
   "source": [
    "The bootstrap approach can be used to assess the variability of the coefficient estimates and predictions from a statistical learning method. Here we use the bootstrap approach in order to assess the variability of the estimates for \n",
    " and \n",
    ", the intercept and slope terms for the linear regression model that uses horsepower to predict mpg in the Auto data set\n",
    "\n",
    "We start by writing a generic function `boot_OLS()` for bootstrapping a regression model that takes a formula to define the corresponding regression. We use the `clone()` function to make a copy of the formula that can be refit to the new dataframe. This means that any derived features such as those defined by `poly()` which will be re-fit on the resampled data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14434d6e-89ec-4133-8898-85d4ad811dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params\n",
    "\n",
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')\n",
    "\n",
    "# Use the hp_func() function to create bootstrap estimates for the intercept and slope \n",
    "rng = np.random.default_rng(0)\n",
    "np.array([hp_func(Auto,\n",
    "          rng.choice(392,\n",
    "                     392,\n",
    "                     replace=True)) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94384a9f-5e10-4854-9f89-1cce12b51731",
   "metadata": {},
   "source": [
    "Next, we use the `boot_SE()` {} function to compute the standard errors of 1,000 bootstrap estimates for the intercept and slope terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483dee5f-e600-482f-b41f-b324570225d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_se = boot_SE(hp_func,\n",
    "                Auto,\n",
    "                B=1000,\n",
    "                seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5748d1ef-eb30-4538-85b3-78c619eb4d71",
   "metadata": {},
   "source": [
    "The bootstrap estimate for ${\\rm SE}(\\hat{\\beta}_0)$ is\n",
    "0.85, and that the bootstrap\n",
    "estimate for ${\\rm SE}(\\hat{\\beta}_1)$ is\n",
    "0.0074. Standard formulas can be used to compute the standard errors for the regression coefficients in a linear model. These can be obtained using the `summarize()` function from `ISLP.sm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fca2a-d45e-47d8-ac66-5aa0b110f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "                      MS(['horsepower']))\n",
    "\n",
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80895997-b92f-46e0-a329-d9bff98d8957",
   "metadata": {},
   "source": [
    "The standard error estimates for $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ are 0.717 for the intercept and 0.006 for the slope.\n",
    "\n",
    "Now, we want to compute the boostrap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde4625-8e96-404b-a4e2-89ecf2f6faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS,\n",
    "                    quad_model,\n",
    "                    'mpg')\n",
    "boot_SE(quad_func, Auto, B=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9be038-2582-4e02-81f7-e420b579127c",
   "metadata": {},
   "source": [
    "We compare the results to the standard errors computed using `sm.OLS()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94305c4-bfe3-4d56-b7d3-7c00a3d9b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = sm.OLS(Auto['mpg'],\n",
    "           quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c6959-9713-480a-bbe7-b58502a9d49f",
   "metadata": {},
   "source": [
    "*These exercises were adapted from :* James, Gareth, et al. An Introduction to Statistical Learning: with Applications in Python, Springer, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi",
   "language": "python",
   "name": "dsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
